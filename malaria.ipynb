{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blueorchid1711/malaria/blob/main/malaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTaw0GTOAB20",
        "outputId": "68e3bf02-3ea1-4c50-eb2d-39cbdeb91472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'cell-images-for-detecting-malaria' dataset.\n",
            "Path to dataset files: /kaggle/input/cell-images-for-detecting-malaria\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8626a14",
        "outputId": "83691fe5-ff3f-4d93-d23e-1848857c1251"
      },
      "source": [
        "final_val_accuracy = history.history['val_accuracy'][-1]\n",
        "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Validation Accuracy: 0.8884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMQJW6KAAMr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c15e23e"
      },
      "source": [
        "# Task\n",
        "Build and evaluate an image classification model for malaria detection using the dataset located at `/kaggle/input/cell-images-for-detecting-malaria`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0262487c"
      },
      "source": [
        "## Prepare Data for Training\n",
        "\n",
        "### Subtask:\n",
        "Set up data generators for training and validation. This includes applying data augmentation techniques to the training data and resizing images to the input size expected by MobileNetV2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "677e6ab0"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define constants and import necessary libraries before setting up the data generators. This includes specifying the image dimensions, batch size, and the path to the dataset. These constants will be used in subsequent steps for configuring the data generators.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63345c11",
        "outputId": "6165ab40-23c9-4730-ea0b-53e1575f43bb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define constants\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "BATCH_SIZE = 32\n",
        "DATA_DIR = '/kaggle/input/cell-images-for-detecting-malaria/cell_images'\n",
        "\n",
        "print(f\"Image size: {IMAGE_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Dataset directory: {DATA_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (224, 224)\n",
            "Batch size: 32\n",
            "Dataset directory: /kaggle/input/cell-images-for-detecting-malaria/cell_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56353475"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the constants are defined, I will create the ImageDataGenerator for the training set, incorporating data augmentation techniques and setting a validation split for later use. This generator will handle the preprocessing and augmentation of training images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6924b5a0",
        "outputId": "e273d72b-bdd2-4a9a-fce5-0e404e045e5a"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2 # 20% for validation\n",
        ")\n",
        "\n",
        "print(\"Training data generator created with augmentation and validation split.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data generator created with augmentation and validation split.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88809dca"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, I need to create a separate `ImageDataGenerator` for the validation set. This generator will only rescale the images and use the same validation split, but without any data augmentation, to ensure the validation data represents the real-world distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85435cf8",
        "outputId": "d7a061a7-704e-4ddf-804a-b6451aa1e090"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2 # Same split as training for consistency\n",
        ")\n",
        "\n",
        "print(\"Validation data generator created without augmentation, only rescaling.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation data generator created without augmentation, only rescaling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0edf884"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that both `ImageDataGenerator` instances are set up, I will generate the training data using `flow_from_directory` on the `train_datagen`. This will load images from the specified `DATA_DIR`, apply augmentation, resize them, and organize them into batches for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "6e49f87d",
        "outputId": "cf5b38cf-e77b-4ed0-c491-db136879185b"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "print(f\"Found {train_generator.samples} training images belonging to {train_generator.num_classes} classes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/cell-images-for-detecting-malaria/cell_images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1739317046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/cell-images-for-detecting-malaria/cell_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1967b901"
      },
      "source": [
        "**Reasoning**:\n",
        "The `FileNotFoundError` indicates that the `DATA_DIR` path as currently defined (`/kaggle/input/cell-images-for-detecting-malaria/cell_images`) does not exist. The `path` variable, which was obtained from `kagglehub.dataset_download`, points to `/kaggle/input/cell-images-for-detecting-malaria`. It is highly probable that the class subdirectories (`Parasitized` and `Uninfected`) are directly within this `path` directory, rather than nested under an additional `cell_images` folder. Therefore, `DATA_DIR` should be set directly to the `path` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "a957eb92",
        "outputId": "184ee54e-934f-4461-9a3c-b7002e7550a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define constants\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "BATCH_SIZE = 32\n",
        "# Corrected DATA_DIR to use the 'path' variable from the dataset download\n",
        "# Assuming 'path' points to the directory containing 'Parasitized' and 'Uninfected' subdirectories\n",
        "DATA_DIR = path\n",
        "\n",
        "print(f\"Image size: {IMAGE_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Dataset directory: {DATA_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-918285829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Corrected DATA_DIR to use the 'path' variable from the dataset download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Assuming 'path' points to the directory containing 'Parasitized' and 'Uninfected' subdirectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image size: {IMAGE_SIZE}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cc491f0"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` indicates that the variable `path` was not defined when `DATA_DIR = path` was executed. This happened because the cell defining `path` (from `kagglehub.dataset_download`) was not executed before or its value was lost. To fix this, I need to re-execute the `kagglehub.dataset_download` to ensure `path` is properly defined before it is used to set `DATA_DIR`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7400f42",
        "outputId": "2c335e83-3f45-48d5-bb42-e2835ecde9a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version to ensure 'path' is defined\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "\n",
        "# Define constants\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "BATCH_SIZE = 32\n",
        "# Corrected DATA_DIR to use the 'path' variable from the dataset download\n",
        "# Assuming 'path' points to the directory containing 'Parasitized' and 'Uninfected' subdirectories\n",
        "DATA_DIR = path\n",
        "\n",
        "print(f\"Image size: {IMAGE_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Dataset directory: {DATA_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/iarunava/cell-images-for-detecting-malaria?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 675M/675M [00:05<00:00, 119MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (224, 224)\n",
            "Batch size: 32\n",
            "Dataset directory: /root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80363fb2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `DATA_DIR` has been correctly defined and `path` is accessible, I will re-attempt to generate the training data using `flow_from_directory`. This should now correctly locate the image directories and create the `train_generator`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2044c51",
        "outputId": "9361298a-3358-4718-8964-24ed2169065d"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "print(f\"Found {train_generator.samples} training images belonging to {train_generator.num_classes} classes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 44093 images belonging to 1 classes.\n",
            "Found 44093 training images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6def220d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output indicates that the `train_generator` found 44093 images but reported '1 classes'. This is incorrect for a binary classification problem (Parasitized/Uninfected) which should have 2 classes. The issue is likely due to the `DATA_DIR` pointing to the root of the dataset which contains an extra directory `cell_images` instead of directly having the `Parasitized` and `Uninfected` subdirectories. I need to correct `DATA_DIR` to point to the `cell_images` subdirectory within the `path` downloaded from KaggleHub.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6702514f",
        "outputId": "800b823b-dc83-4d93-ebba-d2b739c84606"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Re-download to ensure 'path' is defined and up-to-date\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "\n",
        "# Define constants\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "BATCH_SIZE = 32\n",
        "# Corrected DATA_DIR to point to the 'cell_images' subdirectory within the downloaded dataset\n",
        "DATA_DIR = os.path.join(path, 'cell_images')\n",
        "\n",
        "print(f\"Image size: {IMAGE_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Dataset directory: {DATA_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (224, 224)\n",
            "Batch size: 32\n",
            "Dataset directory: /root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10e83c6"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `DATA_DIR` has been correctly updated to include the `cell_images` subdirectory, I need to re-create the `train_generator` to ensure it correctly identifies both classes (Parasitized and Uninfected) and the appropriate number of images for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4c4f54",
        "outputId": "d39936b9-166a-4f0a-d97a-8ebc1de101ee"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "print(f\"Found {train_generator.samples} training images belonging to {train_generator.num_classes} classes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 44095 images belonging to 3 classes.\n",
            "Found 44095 training images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b57c156b"
      },
      "source": [
        "**Reasoning**:\n",
        "The `train_generator` is still reporting 3 classes instead of the expected 2 for binary classification. This indicates an issue with the directory structure within `DATA_DIR` or how `flow_from_directory` is interpreting it. I need to inspect the contents of the `DATA_DIR` to understand what subdirectories are present and causing the '3 classes' count.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9196727",
        "outputId": "41fee20f-cce9-4424-d74d-bda50f79a681"
      },
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the DATA_DIR to check for unexpected subdirectories\n",
        "print(f\"Contents of DATA_DIR ({DATA_DIR}):\")\n",
        "for item in os.listdir(DATA_DIR):\n",
        "    if os.path.isdir(os.path.join(DATA_DIR, item)):\n",
        "        print(f\" - {item}/\")\n",
        "    else:\n",
        "        print(f\" - {item}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of DATA_DIR (/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images):\n",
            " - cell_images/\n",
            " - Uninfected/\n",
            " - Parasitized/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3a66139"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output showed an unexpected nested `cell_images` subdirectory within the current `DATA_DIR`, causing `flow_from_directory` to detect 3 classes. I need to update `DATA_DIR` one more time to point to the correct subdirectory that directly contains 'Parasitized' and 'Uninfected' folders to ensure only two classes are identified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6ec24ee",
        "outputId": "87503410-3b0b-44b3-be3f-56e897aeb3d5"
      },
      "source": [
        "import os\n",
        "\n",
        "# Corrected DATA_DIR to point to the actual directory containing the class folders\n",
        "# The structure appears to be: path/cell_images/cell_images/Parasitized and path/cell_images/cell_images/Uninfected\n",
        "DATA_DIR = os.path.join(path, 'cell_images', 'cell_images')\n",
        "\n",
        "print(f\"Corrected Dataset directory: {DATA_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Dataset directory: /root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images/cell_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9f927b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `DATA_DIR` has been correctly updated to point to the innermost `cell_images` subdirectory, I need to re-create the `train_generator` to ensure it correctly identifies the two class folders ('Parasitized' and 'Uninfected') and the appropriate number of images for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54376cdb",
        "outputId": "7fc0bf19-a136-4fee-97c4-e932bd726054"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "print(f\"Found {train_generator.samples} training images belonging to {train_generator.num_classes} classes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22048 images belonging to 2 classes.\n",
            "Found 22048 training images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abd937f8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the training data generator is correctly set up, I will generate the validation data using `flow_from_directory` on the `validation_datagen`. This will load images from the specified `DATA_DIR`, apply rescaling, resize them, and organize them into batches for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "556d0228",
        "outputId": "0f05f501-52ea-4edd-a403-13a7ee6d80ea"
      },
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(f\"Found {validation_generator.samples} validation images belonging to {validation_generator.num_classes} classes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5510 images belonging to 2 classes.\n",
            "Found 5510 validation images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c561e097"
      },
      "source": [
        "## Build MobileNetV2 Model with Transfer Learning\n",
        "\n",
        "### Subtask:\n",
        "Load the pre-trained MobileNetV2 model as a base and add a custom classification head (dense layers) on top. Freeze the base model layers initially and compile the complete model for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f33de02"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the necessary Keras layers and the MobileNetV2 model to start building the deep learning model as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5c780f9",
        "outputId": "472f72e2-1bd0-442c-b0d6-75aeb844ed29"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "print(\"Keras MobileNetV2, layers, and Model imported successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras MobileNetV2, layers, and Model imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "546fd376"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary libraries are imported, I will load the pre-trained MobileNetV2 model, remove its top classification layer, and freeze its layers to prepare it as the base for transfer learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d422210d",
        "outputId": "85c67b1f-3cd9-4ff5-887a-4e9c01d88884"
      },
      "source": [
        "base_model = MobileNetV2(input_shape=IMAGE_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"MobileNetV2 base model loaded and its layers frozen.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "MobileNetV2 base model loaded and its layers frozen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62bb366"
      },
      "source": [
        "**Reasoning**:\n",
        "With the base model loaded and frozen, I will now create the custom classification head by adding a Flatten layer, a Dense layer with ReLU activation, a BatchNormalization layer, a Dropout layer, and a final Dense layer with sigmoid activation for binary classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d018cb9d",
        "outputId": "9807480f-d804-472f-decb-08bbaa945789"
      },
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "print(\"Custom classification head created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom classification head created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cee3e545"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the base model and the custom classification head are defined, I will combine them into a complete model using the Keras `Model` class, specifying the base model's input and the custom head's output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba22e5cc",
        "outputId": "d1111c2f-6197-483d-9070-59989c9a15fb"
      },
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "print(\"Complete model combining base model and custom head created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete model combining base model and custom head created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7366acf3"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the complete model is assembled, I will compile it using the Adam optimizer with a specified learning rate, binary crossentropy as the loss function, and accuracy as the metric, as required for binary classification tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf543b49",
        "outputId": "cd96c7ca-25cd-4275-be88-01db099dd08d"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled successfully with Adam optimizer, binary_crossentropy loss, and accuracy metric.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled successfully with Adam optimizer, binary_crossentropy loss, and accuracy metric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65f34718"
      },
      "source": [
        "## Train the Image Classification Model\n",
        "\n",
        "### Subtask:\n",
        "Train the configured MobileNetV2 model using the prepared data generators for 8 epochs, as requested. The training will utilize transfer learning techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f1490ac"
      },
      "source": [
        "**Reasoning**:\n",
        "Before training the model, I need to calculate the `steps_per_epoch` using the total number of training samples and the `BATCH_SIZE`. This ensures that each epoch processes the entire training dataset correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9046b9a6",
        "outputId": "cf4ff779-dacc-4c06-8a14-a6fa900a344b"
      },
      "source": [
        "import math\n",
        "\n",
        "steps_per_epoch = math.ceil(train_generator.samples / BATCH_SIZE)\n",
        "\n",
        "print(f\"Calculated steps per epoch: {steps_per_epoch}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated steps per epoch: 689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369df198"
      },
      "source": [
        "\n",
        "**Reasoning**:\n",
        "Now I will calculate the `validation_steps` using the total number of validation samples and the `BATCH_SIZE`. This is necessary for the model's `.fit()` method to correctly iterate through the validation data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69bd12c4",
        "outputId": "45c18c3b-c673-44cc-fea3-2f12304e9a79"
      },
      "source": [
        "validation_steps = math.ceil(validation_generator.samples / BATCH_SIZE)\n",
        "\n",
        "print(f\"Calculated validation steps: {validation_steps}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated validation steps: 173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ab8b5be"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that both `steps_per_epoch` and `validation_steps` are calculated, I will train the model using the `.fit()` method with the prepared data generators and the specified number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7b86be0",
        "outputId": "8ef1b527-d4a7-4d30-b967-3c8b91bdd901"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=8,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "print(\"Model training completed for 8 epochs.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 430ms/step - accuracy: 0.8589 - loss: 0.3477 - val_accuracy: 0.9018 - val_loss: 0.2583\n",
            "Epoch 2/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 399ms/step - accuracy: 0.8989 - loss: 0.2699 - val_accuracy: 0.8938 - val_loss: 0.2763\n",
            "Epoch 3/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 399ms/step - accuracy: 0.9050 - loss: 0.2514 - val_accuracy: 0.8820 - val_loss: 0.3113\n",
            "Epoch 4/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 393ms/step - accuracy: 0.9066 - loss: 0.2444 - val_accuracy: 0.8984 - val_loss: 0.2690\n",
            "Epoch 5/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 391ms/step - accuracy: 0.9155 - loss: 0.2302 - val_accuracy: 0.8677 - val_loss: 0.3532\n",
            "Epoch 6/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 390ms/step - accuracy: 0.9115 - loss: 0.2398 - val_accuracy: 0.9002 - val_loss: 0.2598\n",
            "Epoch 7/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 390ms/step - accuracy: 0.9138 - loss: 0.2351 - val_accuracy: 0.8623 - val_loss: 0.3680\n",
            "Epoch 8/8\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 394ms/step - accuracy: 0.9147 - loss: 0.2257 - val_accuracy: 0.8884 - val_loss: 0.2897\n",
            "Model training completed for 8 epochs.\n"
          ]
        }
      ]
    }
  ]
}